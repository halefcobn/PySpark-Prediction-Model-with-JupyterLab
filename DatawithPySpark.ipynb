{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/halef/opt/anaconda3/lib/python3.9/site-packages (3.3.0)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /Users/halef/opt/anaconda3/lib/python3.9/site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyspark\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.231.37:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8816912cd0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"smoke_detection_iot.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv(path,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string, _c12: string, _c13: string, _c14: string, _c15: string]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+----+----------+\n",
      "| _c0|       _c1|           _c2|        _c3|      _c4|      _c5|   _c6|        _c7|          _c8|  _c9| _c10| _c11| _c12| _c13|_c14|      _c15|\n",
      "+----+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+----+----------+\n",
      "|null|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]|PM1.0|PM2.5|NC0.5|NC1.0|NC2.5| CNT|Fire Alarm|\n",
      "|   0|1654733331|          20.0|      57.36|        0|      400| 12306|      18520|      939.735|  0.0|  0.0|  0.0|  0.0|  0.0|   0|         0|\n",
      "|   1|1654733332|        20.015|      56.67|        0|      400| 12345|      18651|      939.744|  0.0|  0.0|  0.0|  0.0|  0.0|   1|         0|\n",
      "|   2|1654733333|        20.029|      55.96|        0|      400| 12374|      18764|      939.738|  0.0|  0.0|  0.0|  0.0|  0.0|   2|         0|\n",
      "|   3|1654733334|        20.044|      55.28|        0|      400| 12390|      18849|      939.736|  0.0|  0.0|  0.0|  0.0|  0.0|   3|         0|\n",
      "|   4|1654733335|        20.059|      54.69|        0|      400| 12403|      18921|      939.744|  0.0|  0.0|  0.0|  0.0|  0.0|   4|         0|\n",
      "|   5|1654733336|        20.073|      54.12|        0|      400| 12419|      18998|      939.725|  0.0|  0.0|  0.0|  0.0|  0.0|   5|         0|\n",
      "|   6|1654733337|        20.088|      53.61|        0|      400| 12432|      19058|      939.738|  0.0|  0.0|  0.0|  0.0|  0.0|   6|         0|\n",
      "|   7|1654733338|        20.103|       53.2|        0|      400| 12439|      19114|      939.758|  0.0|  0.0|  0.0|  0.0|  0.0|   7|         0|\n",
      "|   8|1654733339|        20.117|      52.81|        0|      400| 12448|      19155|      939.758|  0.0|  0.0|  0.0|  0.0|  0.0|   8|         0|\n",
      "|   9|1654733340|        20.132|      52.46|        0|      400| 12453|      19195|      939.756|  0.9| 3.78|  0.0|4.369| 2.78|   9|         0|\n",
      "|  10|1654733341|        20.146|      52.15|        0|      400| 12454|      19230|      939.757| 0.89| 3.71|  0.0|4.289| 2.73|  10|         0|\n",
      "|  11|1654733342|        20.161|      51.84|        0|      400| 12467|      19264|      939.754| 0.84| 3.51|  0.0|4.053| 2.58|  11|         0|\n",
      "|  12|1654733343|        20.175|      51.62|        0|      400| 12467|      19299|      939.755| 0.81| 3.38|  0.0|3.909|2.488|  12|         0|\n",
      "|  13|1654733344|         20.19|      51.39|        0|      400| 12469|      19317|      939.758| 0.74| 3.11|  0.0|3.588|2.284|  13|         0|\n",
      "|  14|1654733345|        20.204|      51.17|        0|      403| 12468|      19338|      939.742| 0.71| 2.96|  0.0|3.419|2.176|  14|         0|\n",
      "|  15|1654733346|        20.219|      50.99|        0|      400| 12475|      19362|      939.741| 0.64| 2.66|  0.0|3.077|1.959|  15|         0|\n",
      "|  16|1654733347|        20.233|      50.86|        0|      400| 12480|      19382|      939.758|  0.6| 2.52|  0.0|2.908|1.851|  16|         0|\n",
      "|  17|1654733348|        20.248|      50.66|        0|      400| 12477|      19400|      939.764| 0.53| 2.23|  0.0| 2.58|1.642|  17|         0|\n",
      "|  18|1654733349|        20.262|      50.49|        0|      400| 12481|      19422|      939.761|  0.5|  2.1|  0.0|2.423|1.542|  18|         0|\n",
      "+----+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 13:29:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+---+----------+\n",
      "|_c0|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]|PM1.0|PM2.5|NC0.5|NC1.0|NC2.5|CNT|Fire Alarm|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+---+----------+\n",
      "|  0|1654733331|          20.0|      57.36|        0|      400| 12306|      18520|      939.735|  0.0|  0.0|  0.0|  0.0|  0.0|  0|         0|\n",
      "|  1|1654733332|        20.015|      56.67|        0|      400| 12345|      18651|      939.744|  0.0|  0.0|  0.0|  0.0|  0.0|  1|         0|\n",
      "|  2|1654733333|        20.029|      55.96|        0|      400| 12374|      18764|      939.738|  0.0|  0.0|  0.0|  0.0|  0.0|  2|         0|\n",
      "|  3|1654733334|        20.044|      55.28|        0|      400| 12390|      18849|      939.736|  0.0|  0.0|  0.0|  0.0|  0.0|  3|         0|\n",
      "|  4|1654733335|        20.059|      54.69|        0|      400| 12403|      18921|      939.744|  0.0|  0.0|  0.0|  0.0|  0.0|  4|         0|\n",
      "|  5|1654733336|        20.073|      54.12|        0|      400| 12419|      18998|      939.725|  0.0|  0.0|  0.0|  0.0|  0.0|  5|         0|\n",
      "|  6|1654733337|        20.088|      53.61|        0|      400| 12432|      19058|      939.738|  0.0|  0.0|  0.0|  0.0|  0.0|  6|         0|\n",
      "|  7|1654733338|        20.103|       53.2|        0|      400| 12439|      19114|      939.758|  0.0|  0.0|  0.0|  0.0|  0.0|  7|         0|\n",
      "|  8|1654733339|        20.117|      52.81|        0|      400| 12448|      19155|      939.758|  0.0|  0.0|  0.0|  0.0|  0.0|  8|         0|\n",
      "|  9|1654733340|        20.132|      52.46|        0|      400| 12453|      19195|      939.756|  0.9| 3.78|  0.0|4.369| 2.78|  9|         0|\n",
      "| 10|1654733341|        20.146|      52.15|        0|      400| 12454|      19230|      939.757| 0.89| 3.71|  0.0|4.289| 2.73| 10|         0|\n",
      "| 11|1654733342|        20.161|      51.84|        0|      400| 12467|      19264|      939.754| 0.84| 3.51|  0.0|4.053| 2.58| 11|         0|\n",
      "| 12|1654733343|        20.175|      51.62|        0|      400| 12467|      19299|      939.755| 0.81| 3.38|  0.0|3.909|2.488| 12|         0|\n",
      "| 13|1654733344|         20.19|      51.39|        0|      400| 12469|      19317|      939.758| 0.74| 3.11|  0.0|3.588|2.284| 13|         0|\n",
      "| 14|1654733345|        20.204|      51.17|        0|      403| 12468|      19338|      939.742| 0.71| 2.96|  0.0|3.419|2.176| 14|         0|\n",
      "| 15|1654733346|        20.219|      50.99|        0|      400| 12475|      19362|      939.741| 0.64| 2.66|  0.0|3.077|1.959| 15|         0|\n",
      "| 16|1654733347|        20.233|      50.86|        0|      400| 12480|      19382|      939.758|  0.6| 2.52|  0.0|2.908|1.851| 16|         0|\n",
      "| 17|1654733348|        20.248|      50.66|        0|      400| 12477|      19400|      939.764| 0.53| 2.23|  0.0| 2.58|1.642| 17|         0|\n",
      "| 18|1654733349|        20.262|      50.49|        0|      400| 12481|      19422|      939.761|  0.5|  2.1|  0.0|2.423|1.542| 18|         0|\n",
      "| 19|1654733350|        20.277|      50.27|        0|      406| 12489|      19451|      939.752| 0.41| 1.72|  0.0|1.987|1.265| 19|         0|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option(\"header\",\"True\").csv(path).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option(\"header\",\"True\").csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_func():\n",
    "    return pd.read_csv(path,sep=\",\")\n",
    "\n",
    "type(new_func())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UTC</th>\n",
       "      <th>Temperature[C]</th>\n",
       "      <th>Humidity[%]</th>\n",
       "      <th>TVOC[ppb]</th>\n",
       "      <th>eCO2[ppm]</th>\n",
       "      <th>Raw H2</th>\n",
       "      <th>Raw Ethanol</th>\n",
       "      <th>Pressure[hPa]</th>\n",
       "      <th>PM1.0</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>NC0.5</th>\n",
       "      <th>NC1.0</th>\n",
       "      <th>NC2.5</th>\n",
       "      <th>CNT</th>\n",
       "      <th>Fire Alarm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1654733331</td>\n",
       "      <td>20.000</td>\n",
       "      <td>57.36</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12306</td>\n",
       "      <td>18520</td>\n",
       "      <td>939.735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1654733332</td>\n",
       "      <td>20.015</td>\n",
       "      <td>56.67</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12345</td>\n",
       "      <td>18651</td>\n",
       "      <td>939.744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1654733333</td>\n",
       "      <td>20.029</td>\n",
       "      <td>55.96</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>12374</td>\n",
       "      <td>18764</td>\n",
       "      <td>939.738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         UTC  Temperature[C]  Humidity[%]  TVOC[ppb]  eCO2[ppm]  \\\n",
       "0           0  1654733331          20.000        57.36          0        400   \n",
       "1           1  1654733332          20.015        56.67          0        400   \n",
       "2           2  1654733333          20.029        55.96          0        400   \n",
       "\n",
       "   Raw H2  Raw Ethanol  Pressure[hPa]  PM1.0  PM2.5  NC0.5  NC1.0  NC2.5  CNT  \\\n",
       "0   12306        18520        939.735    0.0    0.0    0.0    0.0    0.0    0   \n",
       "1   12345        18651        939.744    0.0    0.0    0.0    0.0    0.0    1   \n",
       "2   12374        18764        939.738    0.0    0.0    0.0    0.0    0.0    2   \n",
       "\n",
       "   Fire Alarm  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(path,sep=\",\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 13:29:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0='0', UTC='1654733331', Temperature[C]='20.0', Humidity[%]='57.36', TVOC[ppb]='0', eCO2[ppm]='400', Raw H2='12306', Raw Ethanol='18520', Pressure[hPa]='939.735', PM1.0='0.0', PM2.5='0.0', NC0.5='0.0', NC1.0='0.0', NC2.5='0.0', CNT='0', Fire Alarm='0'),\n",
       " Row(_c0='1', UTC='1654733332', Temperature[C]='20.015', Humidity[%]='56.67', TVOC[ppb]='0', eCO2[ppm]='400', Raw H2='12345', Raw Ethanol='18651', Pressure[hPa]='939.744', PM1.0='0.0', PM2.5='0.0', NC0.5='0.0', NC1.0='0.0', NC2.5='0.0', CNT='1', Fire Alarm='0')]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- UTC: string (nullable = true)\n",
      " |-- Temperature[C]: string (nullable = true)\n",
      " |-- Humidity[%]: string (nullable = true)\n",
      " |-- TVOC[ppb]: string (nullable = true)\n",
      " |-- eCO2[ppm]: string (nullable = true)\n",
      " |-- Raw H2: string (nullable = true)\n",
      " |-- Raw Ethanol: string (nullable = true)\n",
      " |-- Pressure[hPa]: string (nullable = true)\n",
      " |-- PM1.0: string (nullable = true)\n",
      " |-- PM2.5: string (nullable = true)\n",
      " |-- NC0.5: string (nullable = true)\n",
      " |-- NC1.0: string (nullable = true)\n",
      " |-- NC2.5: string (nullable = true)\n",
      " |-- CNT: string (nullable = true)\n",
      " |-- Fire Alarm: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema() # it is like a df.info in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option(\"Header\",\"True\").csv(path,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- UTC: integer (nullable = true)\n",
      " |-- Temperature[C]: double (nullable = true)\n",
      " |-- Humidity[%]: double (nullable = true)\n",
      " |-- TVOC[ppb]: integer (nullable = true)\n",
      " |-- eCO2[ppm]: integer (nullable = true)\n",
      " |-- Raw H2: integer (nullable = true)\n",
      " |-- Raw Ethanol: integer (nullable = true)\n",
      " |-- Pressure[hPa]: double (nullable = true)\n",
      " |-- PM1.0: double (nullable = true)\n",
      " |-- PM2.5: double (nullable = true)\n",
      " |-- NC0.5: double (nullable = true)\n",
      " |-- NC1.0: double (nullable = true)\n",
      " |-- NC2.5: double (nullable = true)\n",
      " |-- CNT: integer (nullable = true)\n",
      " |-- Fire Alarm: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv(path,header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- UTC: integer (nullable = true)\n",
      " |-- Temperature[C]: double (nullable = true)\n",
      " |-- Humidity[%]: double (nullable = true)\n",
      " |-- TVOC[ppb]: integer (nullable = true)\n",
      " |-- eCO2[ppm]: integer (nullable = true)\n",
      " |-- Raw H2: integer (nullable = true)\n",
      " |-- Raw Ethanol: integer (nullable = true)\n",
      " |-- Pressure[hPa]: double (nullable = true)\n",
      " |-- PM1.0: double (nullable = true)\n",
      " |-- PM2.5: double (nullable = true)\n",
      " |-- NC0.5: double (nullable = true)\n",
      " |-- NC1.0: double (nullable = true)\n",
      " |-- NC2.5: double (nullable = true)\n",
      " |-- CNT: integer (nullable = true)\n",
      " |-- Fire Alarm: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 13:30:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+---+----------+\n",
      "|_c0|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]|PM1.0|PM2.5|NC0.5|NC1.0|NC2.5|CNT|Fire Alarm|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+---+----------+\n",
      "|  0|1654733331|          20.0|      57.36|        0|      400| 12306|      18520|      939.735|  0.0|  0.0|  0.0|  0.0|  0.0|  0|         0|\n",
      "|  1|1654733332|        20.015|      56.67|        0|      400| 12345|      18651|      939.744|  0.0|  0.0|  0.0|  0.0|  0.0|  1|         0|\n",
      "|  2|1654733333|        20.029|      55.96|        0|      400| 12374|      18764|      939.738|  0.0|  0.0|  0.0|  0.0|  0.0|  2|         0|\n",
      "|  3|1654733334|        20.044|      55.28|        0|      400| 12390|      18849|      939.736|  0.0|  0.0|  0.0|  0.0|  0.0|  3|         0|\n",
      "|  4|1654733335|        20.059|      54.69|        0|      400| 12403|      18921|      939.744|  0.0|  0.0|  0.0|  0.0|  0.0|  4|         0|\n",
      "|  5|1654733336|        20.073|      54.12|        0|      400| 12419|      18998|      939.725|  0.0|  0.0|  0.0|  0.0|  0.0|  5|         0|\n",
      "|  6|1654733337|        20.088|      53.61|        0|      400| 12432|      19058|      939.738|  0.0|  0.0|  0.0|  0.0|  0.0|  6|         0|\n",
      "|  7|1654733338|        20.103|       53.2|        0|      400| 12439|      19114|      939.758|  0.0|  0.0|  0.0|  0.0|  0.0|  7|         0|\n",
      "|  8|1654733339|        20.117|      52.81|        0|      400| 12448|      19155|      939.758|  0.0|  0.0|  0.0|  0.0|  0.0|  8|         0|\n",
      "|  9|1654733340|        20.132|      52.46|        0|      400| 12453|      19195|      939.756|  0.9| 3.78|  0.0|4.369| 2.78|  9|         0|\n",
      "| 10|1654733341|        20.146|      52.15|        0|      400| 12454|      19230|      939.757| 0.89| 3.71|  0.0|4.289| 2.73| 10|         0|\n",
      "| 11|1654733342|        20.161|      51.84|        0|      400| 12467|      19264|      939.754| 0.84| 3.51|  0.0|4.053| 2.58| 11|         0|\n",
      "| 12|1654733343|        20.175|      51.62|        0|      400| 12467|      19299|      939.755| 0.81| 3.38|  0.0|3.909|2.488| 12|         0|\n",
      "| 13|1654733344|         20.19|      51.39|        0|      400| 12469|      19317|      939.758| 0.74| 3.11|  0.0|3.588|2.284| 13|         0|\n",
      "| 14|1654733345|        20.204|      51.17|        0|      403| 12468|      19338|      939.742| 0.71| 2.96|  0.0|3.419|2.176| 14|         0|\n",
      "| 15|1654733346|        20.219|      50.99|        0|      400| 12475|      19362|      939.741| 0.64| 2.66|  0.0|3.077|1.959| 15|         0|\n",
      "| 16|1654733347|        20.233|      50.86|        0|      400| 12480|      19382|      939.758|  0.6| 2.52|  0.0|2.908|1.851| 16|         0|\n",
      "| 17|1654733348|        20.248|      50.66|        0|      400| 12477|      19400|      939.764| 0.53| 2.23|  0.0| 2.58|1.642| 17|         0|\n",
      "| 18|1654733349|        20.262|      50.49|        0|      400| 12481|      19422|      939.761|  0.5|  2.1|  0.0|2.423|1.542| 18|         0|\n",
      "| 19|1654733350|        20.277|      50.27|        0|      406| 12489|      19451|      939.752| 0.41| 1.72|  0.0|1.987|1.265| 19|         0|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+-----+-----+-----+-----+-----+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- UTC: integer (nullable = true)\n",
      " |-- Temperature[C]: double (nullable = true)\n",
      " |-- Humidity[%]: double (nullable = true)\n",
      " |-- TVOC[ppb]: integer (nullable = true)\n",
      " |-- eCO2[ppm]: integer (nullable = true)\n",
      " |-- Raw H2: integer (nullable = true)\n",
      " |-- Raw Ethanol: integer (nullable = true)\n",
      " |-- Pressure[hPa]: double (nullable = true)\n",
      " |-- PM1.0: double (nullable = true)\n",
      " |-- PM2.5: double (nullable = true)\n",
      " |-- NC0.5: double (nullable = true)\n",
      " |-- NC1.0: double (nullable = true)\n",
      " |-- NC2.5: double (nullable = true)\n",
      " |-- CNT: integer (nullable = true)\n",
      " |-- Fire Alarm: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'UTC',\n",
       " 'Temperature[C]',\n",
       " 'Humidity[%]',\n",
       " 'TVOC[ppb]',\n",
       " 'eCO2[ppm]',\n",
       " 'Raw H2',\n",
       " 'Raw Ethanol',\n",
       " 'Pressure[hPa]',\n",
       " 'PM1.0',\n",
       " 'PM2.5',\n",
       " 'NC0.5',\n",
       " 'NC1.0',\n",
       " 'NC2.5',\n",
       " 'CNT',\n",
       " 'Fire Alarm']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Temperature[C]: double]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select(\"Temperature[C]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Raw H2|\n",
      "+------+\n",
      "| 12306|\n",
      "| 12345|\n",
      "| 12374|\n",
      "| 12390|\n",
      "| 12403|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(\"Raw H2\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|Humidity[%]|Raw H2|\n",
      "+-----------+------+\n",
      "|      57.36| 12306|\n",
      "|      56.67| 12345|\n",
      "|      55.96| 12374|\n",
      "|      55.28| 12390|\n",
      "|      54.69| 12403|\n",
      "+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Humidity[%]','Raw H2']).show(5) # Selecting the two columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Humidity[%]'>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['Humidity[%]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'),\n",
       " ('UTC', 'int'),\n",
       " ('Temperature[C]', 'double'),\n",
       " ('Humidity[%]', 'double'),\n",
       " ('TVOC[ppb]', 'int'),\n",
       " ('eCO2[ppm]', 'int'),\n",
       " ('Raw H2', 'int'),\n",
       " ('Raw Ethanol', 'int'),\n",
       " ('Pressure[hPa]', 'double'),\n",
       " ('PM1.0', 'double'),\n",
       " ('PM2.5', 'double'),\n",
       " ('NC0.5', 'double'),\n",
       " ('NC1.0', 'double'),\n",
       " ('NC2.5', 'double'),\n",
       " ('CNT', 'int'),\n",
       " ('Fire Alarm', 'int')]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 13:30:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 75:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-------------------+\n",
      "|summary|              _c0|                 UTC|    Temperature[C]|       Humidity[%]|         TVOC[ppb]|         eCO2[ppm]|            Raw H2|       Raw Ethanol|     Pressure[hPa]|             PM1.0|             PM2.5|             NC0.5|             NC1.0|             NC2.5|              CNT|         Fire Alarm|\n",
      "+-------+-----------------+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-------------------+\n",
      "|  count|            62630|               62630|             62630|             62630|             62630|             62630|             62630|             62630|             62630|             62630|             62630|             62630|             62630|             62630|            62630|              62630|\n",
      "|   mean|          31314.5|1.6547920661842728E9|15.970423582947525|48.539499441162555|1942.0575283410506| 670.0210442280057|12942.453935813508|19754.257911543988| 938.6276494651111|100.59430911703662|184.46777023790557|491.46360769599147|203.58648749800415| 80.04904232795866|10511.38615679387| 0.7146255787961041|\n",
      "| stddev|18079.86801666428|   110002.4880758493|14.359576152610815| 8.865367089675326| 7811.589055386011|1905.8854393506053|272.46430523531353| 609.5131564626514|1.3313435732426881| 922.5242445867342|1976.3056148260869| 4265.661251435338|2214.7385556394765|1083.3831887688011| 7597.87099737755|0.45159618818066594|\n",
      "|    min|                0|          1654712187|            -22.01|             10.74|                 0|               400|             10668|             15317|           930.852|               0.0|               0.0|               0.0|               0.0|               0.0|                0|                  0|\n",
      "|    max|            62629|          1655130051|             59.93|              75.2|             60000|             60000|             13803|             21410|           939.861|          14333.69|          45432.26|          61482.03|          51914.68|         30026.438|            24993|                  1|\n",
      "+-------+-----------------+--------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show() # because of the data, output does not fit on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "|Temperature[C]|Raw Ethanol|\n",
      "+--------------+-----------+\n",
      "|          20.0|      18520|\n",
      "|        20.015|      18651|\n",
      "|        20.029|      18764|\n",
      "+--------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Temperature[C]',\"Raw Ethanol\"]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|    Temperature[C]|       Raw Ethanol|\n",
      "+-------+------------------+------------------+\n",
      "|  count|             62630|             62630|\n",
      "|   mean|15.970423582947525|19754.257911543988|\n",
      "| stddev|14.359576152610815| 609.5131564626514|\n",
      "|    min|            -22.01|             15317|\n",
      "|    max|             59.93|             21410|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Temperature[C]',\"Raw Ethanol\"]).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output can easily seen on the table as an statistical output.\n",
    "Only two columns are selected to be shown the descrice func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit # to add a none or constant value to the new column, use lit func.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'UTC',\n",
       " 'Temperature[C]',\n",
       " 'Humidity[%]',\n",
       " 'TVOC[ppb]',\n",
       " 'eCO2[ppm]',\n",
       " 'Raw H2',\n",
       " 'Raw Ethanol',\n",
       " 'Pressure[hPa]',\n",
       " 'PM1.0',\n",
       " 'PM2.5',\n",
       " 'NC0.5',\n",
       " 'NC1.0',\n",
       " 'NC2.5',\n",
       " 'CNT',\n",
       " 'Fire Alarm',\n",
       " 'New Column']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.withColumn(\"New Column\", lit(0)).columns # Add a column with 0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn(\"New Column\", df_pyspark.UTC/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'UTC',\n",
       " 'Temperature[C]',\n",
       " 'Humidity[%]',\n",
       " 'TVOC[ppb]',\n",
       " 'eCO2[ppm]',\n",
       " 'Raw H2',\n",
       " 'Raw Ethanol',\n",
       " 'Pressure[hPa]',\n",
       " 'PM1.0',\n",
       " 'PM2.5',\n",
       " 'NC0.5',\n",
       " 'NC1.0',\n",
       " 'NC2.5',\n",
       " 'CNT',\n",
       " 'Fire Alarm',\n",
       " 'New Column']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|       UTC|   New Column|\n",
      "+----------+-------------+\n",
      "|1654733331|1.654733331E8|\n",
      "|1654733332|1.654733332E8|\n",
      "|1654733333|1.654733333E8|\n",
      "|1654733334|1.654733334E8|\n",
      "|1654733335|1.654733335E8|\n",
      "+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select([\"UTC\",\"New Column\"]).show(5) # you can see the output showing the diveded values by UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, UTC: int, Temperature[C]: double, Humidity[%]: double, TVOC[ppb]: int, eCO2[ppm]: int, Raw H2: int, Raw Ethanol: int, Pressure[hPa]: double, PM1.0: double, PM2.5: double, NC0.5: double, NC1.0: double, NC2.5: double, CNT: int, Fire Alarm: int]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.drop(\"New Column\") # Dropping a column from DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.drop(\"New Column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'UTC',\n",
       " 'Temperature[C]',\n",
       " 'Humidity[%]',\n",
       " 'TVOC[ppb]',\n",
       " 'eCO2[ppm]',\n",
       " 'Raw H2',\n",
       " 'Raw Ethanol',\n",
       " 'Pressure[hPa]',\n",
       " 'PM1.0',\n",
       " 'PM2.5',\n",
       " 'NC0.5',\n",
       " 'NC1.0',\n",
       " 'NC2.5',\n",
       " 'CNT',\n",
       " 'Fire Alarm']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'Utc',\n",
       " 'Temperature[C]',\n",
       " 'Humidity[%]',\n",
       " 'TVOC[ppb]',\n",
       " 'eCO2[ppm]',\n",
       " 'Raw H2',\n",
       " 'Raw Ethanol',\n",
       " 'Pressure[hPa]',\n",
       " 'PM1.0',\n",
       " 'PM2.5',\n",
       " 'NC0.5',\n",
       " 'NC1.0',\n",
       " 'NC2.5',\n",
       " 'CNT',\n",
       " 'Fire Alarm']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed(\"UTC\",\"Utc\").columns # UTC has been renamed with Utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark= df_pyspark.withColumnRenamed(\"PM1.0\",\"PM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'UTC',\n",
       " 'Temperature[C]',\n",
       " 'Humidity[%]',\n",
       " 'TVOC[ppb]',\n",
       " 'eCO2[ppm]',\n",
       " 'Raw H2',\n",
       " 'Raw Ethanol',\n",
       " 'Pressure[hPa]',\n",
       " 'PM',\n",
       " 'PM2.5',\n",
       " 'NC0.5',\n",
       " 'NC1.0',\n",
       " 'NC2.5',\n",
       " 'CNT',\n",
       " 'Fire Alarm']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"builtin_function_or_method\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/halef/Desktop/Coursera/PySpark/PySpark-1.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/halef/Desktop/Coursera/PySpark/PySpark-1.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_pyspark\u001b[39m.\u001b[39;49mna\u001b[39m.\u001b[39;49mdrop(how\u001b[39m=\u001b[39;49m\u001b[39many\u001b[39;49m, thresh\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\u001b[39m.\u001b[39mshow(\u001b[39m4\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:3408\u001b[0m, in \u001b[0;36mDataFrameNaFunctions.drop\u001b[0;34m(self, how, thresh, subset)\u001b[0m\n\u001b[1;32m   3402\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   3403\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   3404\u001b[0m     how: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39many\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3405\u001b[0m     thresh: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   3406\u001b[0m     subset: Optional[Union[\u001b[39mstr\u001b[39m, Tuple[\u001b[39mstr\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m], List[\u001b[39mstr\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   3407\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m-> 3408\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49mdropna(how\u001b[39m=\u001b[39;49mhow, thresh\u001b[39m=\u001b[39;49mthresh, subset\u001b[39m=\u001b[39;49msubset)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:2440\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[0;34m(self, how, thresh, subset)\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[39m\"\"\"Returns a new :class:`DataFrame` omitting rows with null values.\u001b[39;00m\n\u001b[1;32m   2413\u001b[0m \u001b[39m:func:`DataFrame.dropna` and :func:`DataFrameNaFunctions.drop` are aliases of each other.\u001b[39;00m\n\u001b[1;32m   2414\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[39m+---+------+-----+\u001b[39;00m\n\u001b[1;32m   2438\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2439\u001b[0m \u001b[39mif\u001b[39;00m how \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m how \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39many\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m-> 2440\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39;49m\u001b[39mhow (\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m how \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m) should be \u001b[39m\u001b[39m'\u001b[39m\u001b[39many\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2442\u001b[0m \u001b[39mif\u001b[39;00m subset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2443\u001b[0m     subset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"builtin_function_or_method\") to str"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how=any, thresh=3).show(4) \n",
    "# any meansdropping th eall row with a null value. Thresh is used to delete the rows at leat it has 3 or more null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"builtin_function_or_method\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/halef/Desktop/Coursera/PySpark/PySpark-1.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/halef/Desktop/Coursera/PySpark/PySpark-1.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_pyspark\u001b[39m.\u001b[39;49mna\u001b[39m.\u001b[39;49mdrop(how\u001b[39m=\u001b[39;49m\u001b[39many\u001b[39;49m, subset\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mPM\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mshow(\u001b[39m4\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:3408\u001b[0m, in \u001b[0;36mDataFrameNaFunctions.drop\u001b[0;34m(self, how, thresh, subset)\u001b[0m\n\u001b[1;32m   3402\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   3403\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   3404\u001b[0m     how: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39many\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3405\u001b[0m     thresh: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   3406\u001b[0m     subset: Optional[Union[\u001b[39mstr\u001b[39m, Tuple[\u001b[39mstr\u001b[39m, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m], List[\u001b[39mstr\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   3407\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m-> 3408\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49mdropna(how\u001b[39m=\u001b[39;49mhow, thresh\u001b[39m=\u001b[39;49mthresh, subset\u001b[39m=\u001b[39;49msubset)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:2440\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[0;34m(self, how, thresh, subset)\u001b[0m\n\u001b[1;32m   2412\u001b[0m \u001b[39m\"\"\"Returns a new :class:`DataFrame` omitting rows with null values.\u001b[39;00m\n\u001b[1;32m   2413\u001b[0m \u001b[39m:func:`DataFrame.dropna` and :func:`DataFrameNaFunctions.drop` are aliases of each other.\u001b[39;00m\n\u001b[1;32m   2414\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[39m+---+------+-----+\u001b[39;00m\n\u001b[1;32m   2438\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2439\u001b[0m \u001b[39mif\u001b[39;00m how \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m how \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39many\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m-> 2440\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39;49m\u001b[39mhow (\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m how \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m) should be \u001b[39m\u001b[39m'\u001b[39m\u001b[39many\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2442\u001b[0m \u001b[39mif\u001b[39;00m subset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2443\u001b[0m     subset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"builtin_function_or_method\") to str"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how=any, subset=[\"PM\"]).show(4) \n",
    "# it only deletes the null rows according to PM column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PM: double]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select(\"PM\").na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When how section used, there is an error.\n",
    "I will solve it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 13:30:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "|_c0|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]| PM|PM2.5|NC0.5|NC1.0|NC2.5|CNT|Fire Alarm|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "|  0|1654733331|          20.0|      57.36|        0|      400| 12306|      18520|      939.735|0.0|  0.0|  0.0|  0.0|  0.0|  0|         0|\n",
      "|  1|1654733332|        20.015|      56.67|        0|      400| 12345|      18651|      939.744|0.0|  0.0|  0.0|  0.0|  0.0|  1|         0|\n",
      "|  2|1654733333|        20.029|      55.96|        0|      400| 12374|      18764|      939.738|0.0|  0.0|  0.0|  0.0|  0.0|  2|         0|\n",
      "|  3|1654733334|        20.044|      55.28|        0|      400| 12390|      18849|      939.736|0.0|  0.0|  0.0|  0.0|  0.0|  3|         0|\n",
      "|  4|1654733335|        20.059|      54.69|        0|      400| 12403|      18921|      939.744|0.0|  0.0|  0.0|  0.0|  0.0|  4|         0|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filling the missing values.\n",
    "df_pyspark.na.fill(\"missing values\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 13:30:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "|_c0|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]| PM|PM2.5|NC0.5|NC1.0|NC2.5|CNT|Fire Alarm|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "|  0|1654733331|          20.0|      57.36|        0|      400| 12306|      18520|      939.735|0.0|  0.0|  0.0|  0.0|  0.0|  0|         0|\n",
      "|  1|1654733332|        20.015|      56.67|        0|      400| 12345|      18651|      939.744|0.0|  0.0|  0.0|  0.0|  0.0|  1|         0|\n",
      "|  2|1654733333|        20.029|      55.96|        0|      400| 12374|      18764|      939.738|0.0|  0.0|  0.0|  0.0|  0.0|  2|         0|\n",
      "|  3|1654733334|        20.044|      55.28|        0|      400| 12390|      18849|      939.736|0.0|  0.0|  0.0|  0.0|  0.0|  3|         0|\n",
      "|  4|1654733335|        20.059|      54.69|        0|      400| 12403|      18921|      939.744|0.0|  0.0|  0.0|  0.0|  0.0|  4|         0|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filling the missing values in spesific columns.\n",
    "df_pyspark.na.fill(\"missing values\",[\"PM\",\"Fire Alarm\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "# it is used to take needed value to the null values with creating a new column like _inputed\n",
    "\n",
    "imputer = Imputer(inputCols=[\"PM\",\"Fire Alarm\"],\n",
    "outputCols=[\"{}_inputed\" .format(c) for c in [\"PM\", \"Fire Alarm\"]]).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 13:30:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+----------+------------------+\n",
      "|_c0|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]| PM|PM2.5|NC0.5|NC1.0|NC2.5|CNT|Fire Alarm|PM_inputed|Fire Alarm_inputed|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+----------+------------------+\n",
      "|  0|1654733331|          20.0|      57.36|        0|      400| 12306|      18520|      939.735|0.0|  0.0|  0.0|  0.0|  0.0|  0|         0|       0.0|                 0|\n",
      "|  1|1654733332|        20.015|      56.67|        0|      400| 12345|      18651|      939.744|0.0|  0.0|  0.0|  0.0|  0.0|  1|         0|       0.0|                 0|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'UTC',\n",
       " 'Temperature[C]',\n",
       " 'Humidity[%]',\n",
       " 'TVOC[ppb]',\n",
       " 'eCO2[ppm]',\n",
       " 'Raw H2',\n",
       " 'Raw Ethanol',\n",
       " 'Pressure[hPa]',\n",
       " 'PM',\n",
       " 'PM2.5',\n",
       " 'NC0.5',\n",
       " 'NC1.0',\n",
       " 'NC2.5',\n",
       " 'CNT',\n",
       " 'Fire Alarm']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Opetaions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 13:37:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "|_c0|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]| PM|PM2.5|NC0.5|NC1.0|NC2.5|CNT|Fire Alarm|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "|  0|1654733331|          20.0|      57.36|        0|      400| 12306|      18520|      939.735|0.0|  0.0|  0.0|  0.0|  0.0|  0|         0|\n",
      "|  1|1654733332|        20.015|      56.67|        0|      400| 12345|      18651|      939.744|0.0|  0.0|  0.0|  0.0|  0.0|  1|         0|\n",
      "|  2|1654733333|        20.029|      55.96|        0|      400| 12374|      18764|      939.738|0.0|  0.0|  0.0|  0.0|  0.0|  2|         0|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Temperature[C]|\n",
      "+--------------+\n",
      "|          20.0|\n",
      "|        20.015|\n",
      "|        20.029|\n",
      "|        20.044|\n",
      "|        20.059|\n",
      "|        20.073|\n",
      "|        20.088|\n",
      "|        20.103|\n",
      "|        20.117|\n",
      "|        20.132|\n",
      "|        20.146|\n",
      "|        20.161|\n",
      "|        20.175|\n",
      "|         20.19|\n",
      "|        20.204|\n",
      "|        20.219|\n",
      "|        20.233|\n",
      "|        20.248|\n",
      "|        20.262|\n",
      "|        20.277|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(\"Temperature[C]\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 13:47:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n",
      "+----+----------+--------------+-----------+---------+---------+------+-----------+-------------+----+-----+-----+-----+-----+----+----------+\n",
      "| _c0|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]|  PM|PM2.5|NC0.5|NC1.0|NC2.5| CNT|Fire Alarm|\n",
      "+----+----------+--------------+-----------+---------+---------+------+-----------+-------------+----+-----+-----+-----+-----+----+----------+\n",
      "|2432|1654735763|        18.295|      48.26|       38|      400| 13196|      20120|      939.604|1.19| 1.23| 8.16|1.273|0.029|2432|         0|\n",
      "|2433|1654735764|        18.284|      47.98|       29|      400| 13205|      20137|       939.62|1.21| 1.25|  8.3|1.294|0.029|2433|         0|\n",
      "|2434|1654735765|        18.273|      47.83|       40|      400| 13201|      20123|      939.612|1.21| 1.26| 8.32|1.297|0.029|2434|         0|\n",
      "|2435|1654735766|        18.262|      47.69|       36|      400| 13209|      20126|      939.626|1.17| 1.21| 8.02|1.251|0.028|2435|         0|\n",
      "|2436|1654735767|        18.251|      47.57|       32|      400| 13205|      20127|      939.629|1.14| 1.18| 7.82|1.219|0.028|2436|         0|\n",
      "+----+----------+--------------+-----------+---------+---------+------+-----------+-------------+----+-----+-----+-----+-----+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(df_pyspark[\"Temperature[C]\"]<=18.3).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Humidity[%]|\n",
      "+-----------+\n",
      "|      57.36|\n",
      "|       47.7|\n",
      "|      48.42|\n",
      "+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(df_pyspark[\"Temperature[C]\"]<=20).select([\"Humidity[%]\"]).show(3)\n",
    "# we only took the Humidity whose is temperature is less than and equal 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Humidity[%]|\n",
      "+-----------+\n",
      "|      56.67|\n",
      "|      55.96|\n",
      "|      55.28|\n",
      "+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark[\"Temperature[C]\"]<=20)).select([\"Humidity[%]\"]).show(3)\n",
    "# ~ it is the non operation for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 14:07:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "|_c0|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]| PM|PM2.5|NC0.5|NC1.0|NC2.5|CNT|Fire Alarm|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "|  0|1654733331|          20.0|      57.36|        0|      400| 12306|      18520|      939.735|0.0|  0.0|  0.0|  0.0|  0.0|  0|         0|\n",
      "|  1|1654733332|        20.015|      56.67|        0|      400| 12345|      18651|      939.744|0.0|  0.0|  0.0|  0.0|  0.0|  1|         0|\n",
      "|  2|1654733333|        20.029|      55.96|        0|      400| 12374|      18764|      939.738|0.0|  0.0|  0.0|  0.0|  0.0|  2|         0|\n",
      "|  3|1654733334|        20.044|      55.28|        0|      400| 12390|      18849|      939.736|0.0|  0.0|  0.0|  0.0|  0.0|  3|         0|\n",
      "|  4|1654733335|        20.059|      54.69|        0|      400| 12403|      18921|      939.744|0.0|  0.0|  0.0|  0.0|  0.0|  4|         0|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+---+-----+-----+-----+-----+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|       UTC|count|\n",
      "+----------+-----+\n",
      "|1654733334|    1|\n",
      "|1654733766|    1|\n",
      "|1654733773|    1|\n",
      "|1654733862|    1|\n",
      "|1654734241|    1|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GroupBy function \n",
    "\n",
    "df_pyspark.groupBy(df_pyspark[\"UTC\"]).count().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/16 14:16:29 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      " Schema: _c0, UTC, Temperature[C], Humidity[%], TVOC[ppb], eCO2[ppm], Raw H2, Raw Ethanol, Pressure[hPa], PM1.0, PM2.5, NC0.5, NC1.0, NC2.5, CNT, Fire Alarm\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/halef/Desktop/Coursera/PySpark/smoke_detection_iot.csv\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+----+-----+-----+-----+-----+---+----------+\n",
      "|_c0|       UTC|Temperature[C]|Humidity[%]|TVOC[ppb]|eCO2[ppm]|Raw H2|Raw Ethanol|Pressure[hPa]|  PM|PM2.5|NC0.5|NC1.0|NC2.5|CNT|Fire Alarm|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+----+-----+-----+-----+-----+---+----------+\n",
      "|  0|1654733331|          20.0|      57.36|        0|      400| 12306|      18520|      939.735| 0.0|  0.0|  0.0|  0.0|  0.0|  0|         0|\n",
      "|  1|1654733332|        20.015|      56.67|        0|      400| 12345|      18651|      939.744| 0.0|  0.0|  0.0|  0.0|  0.0|  1|         0|\n",
      "|  2|1654733333|        20.029|      55.96|        0|      400| 12374|      18764|      939.738| 0.0|  0.0|  0.0|  0.0|  0.0|  2|         0|\n",
      "|  3|1654733334|        20.044|      55.28|        0|      400| 12390|      18849|      939.736| 0.0|  0.0|  0.0|  0.0|  0.0|  3|         0|\n",
      "|  4|1654733335|        20.059|      54.69|        0|      400| 12403|      18921|      939.744| 0.0|  0.0|  0.0|  0.0|  0.0|  4|         0|\n",
      "|  5|1654733336|        20.073|      54.12|        0|      400| 12419|      18998|      939.725| 0.0|  0.0|  0.0|  0.0|  0.0|  5|         0|\n",
      "|  6|1654733337|        20.088|      53.61|        0|      400| 12432|      19058|      939.738| 0.0|  0.0|  0.0|  0.0|  0.0|  6|         0|\n",
      "|  7|1654733338|        20.103|       53.2|        0|      400| 12439|      19114|      939.758| 0.0|  0.0|  0.0|  0.0|  0.0|  7|         0|\n",
      "|  8|1654733339|        20.117|      52.81|        0|      400| 12448|      19155|      939.758| 0.0|  0.0|  0.0|  0.0|  0.0|  8|         0|\n",
      "|  9|1654733340|        20.132|      52.46|        0|      400| 12453|      19195|      939.756| 0.9| 3.78|  0.0|4.369| 2.78|  9|         0|\n",
      "| 10|1654733341|        20.146|      52.15|        0|      400| 12454|      19230|      939.757|0.89| 3.71|  0.0|4.289| 2.73| 10|         0|\n",
      "| 11|1654733342|        20.161|      51.84|        0|      400| 12467|      19264|      939.754|0.84| 3.51|  0.0|4.053| 2.58| 11|         0|\n",
      "| 12|1654733343|        20.175|      51.62|        0|      400| 12467|      19299|      939.755|0.81| 3.38|  0.0|3.909|2.488| 12|         0|\n",
      "| 13|1654733344|         20.19|      51.39|        0|      400| 12469|      19317|      939.758|0.74| 3.11|  0.0|3.588|2.284| 13|         0|\n",
      "| 14|1654733345|        20.204|      51.17|        0|      403| 12468|      19338|      939.742|0.71| 2.96|  0.0|3.419|2.176| 14|         0|\n",
      "| 15|1654733346|        20.219|      50.99|        0|      400| 12475|      19362|      939.741|0.64| 2.66|  0.0|3.077|1.959| 15|         0|\n",
      "| 16|1654733347|        20.233|      50.86|        0|      400| 12480|      19382|      939.758| 0.6| 2.52|  0.0|2.908|1.851| 16|         0|\n",
      "| 17|1654733348|        20.248|      50.66|        0|      400| 12477|      19400|      939.764|0.53| 2.23|  0.0| 2.58|1.642| 17|         0|\n",
      "| 18|1654733349|        20.262|      50.49|        0|      400| 12481|      19422|      939.761| 0.5|  2.1|  0.0|2.423|1.542| 18|         0|\n",
      "| 19|1654733350|        20.277|      50.27|        0|      406| 12489|      19451|      939.752|0.41| 1.72|  0.0|1.987|1.265| 19|         0|\n",
      "+---+----------+--------------+-----------+---------+---------+------+-----------+-------------+----+-----+-----+-----+-----+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fe5a750161903c2a52830aabb3d8fea2ca467d671956af063c191e5022af088"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
